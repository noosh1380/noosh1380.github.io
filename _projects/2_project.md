---
layout: page
title: Project 2
description: A Study on Memory Buffers in Reinforcement Learning
img: assets/img/Project2.2.jpg
importance: 2
category: Research
---

A collaborative research project in the field of reinforcement learning conducted at McGill University as part of a graduate-level course: <a href="https://drive.google.com/file/d/1yg1AXV2AbsHC2g6n__JKsteykK50t7W1/view?usp=share_link">A Study on Random and Prioritized Memory Buffer Techniques and Their Performance</a>

<h3>Abstract</h3>

This project explores the efficiency and performance improvements of the Deep Q-network (DQN) algorithm through the implementation and comparison of Random and Prioritized Experience Replay techniques. We aim to empirically assess the impact of both strategies on algorithm performance in various environments, including a a stochastic and a non-stationary gridworld environment. Overall, our findings indicate that Prioritized Experience Replay (PER) can outperform Random Experience Replay(RER) in certain scenarios, suggesting its potential as a valuable strategy for enhancing the learning efficiency of DQN. 

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/Project2.2.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>


